{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aea56ab5",
   "metadata": {},
   "source": [
    "# 네이버 댓글 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb7e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\richard baek\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "# 모듈 import하기\n",
    "!pip install selenium\n",
    "\n",
    "import requests\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd53625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 설정\n",
    "\n",
    "QUERY = \"주52시간\"\n",
    "START_DATE = \"2019.12.25\"\n",
    "END_DATE = \"2019.12.31\"\n",
    "\n",
    "search_QUERY = urllib.parse.urlencode({'query':QUERY}, encoding='utf-8')\n",
    "start_QUERY = urllib.parse.urlencode({'ds':START_DATE}, encoding='utf-8')\n",
    "end_QUERY = urllib.parse.urlencode({'de':END_DATE}, encoding='utf-8')\n",
    "p_QUERY = urllib.parse.urlencode({'p':f\"from{START_DATE.replace('.','')} to {END_DATE.replace('.','')}\"}, encoding='utf-8')\n",
    "\n",
    "URL = f\"https://search.naver.com/search.naver?&where=news&{search_QUERY}&sm=tab_pge&sort=2&photo=0&field=0&reporter_article=&pd=3&{start_QUERY}&{end_QUERY}&docid=&nso=so:da,{p_QUERY},a:all&mynews=0\"\n",
    "LINK_PAT = \"https:\\/\\/news\\.naver\\.com\\/main\\/read\\.nhn\\?\"\n",
    "search_PAGE = 326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c62efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RICHAR~1\\AppData\\Local\\Temp/ipykernel_9700/3132064971.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"E:/chromedriver_win32 (2)/chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "# 드라이브 설정\n",
    "\n",
    "driver = webdriver.Chrome(\"E:/chromedriver_win32 (2)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4fabb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색결과 내 링크 찾기 : news.naver.com으로 시작하는 모든 링크 반환\n",
    "\n",
    "def get_news_links(page_num, link_pattern):\n",
    "    links = []\n",
    "    for page in range(page_num):\n",
    "        print(f\"Scrapping page : {page + 1}\")  # 확인용\n",
    "        req = requests.get(f\"{URL}&start={10 * page + 1}\")\n",
    "        print(req.status_code)  # 확인용\n",
    "        soup = BeautifulSoup(req.text, 'lxml')\n",
    "        results = soup.find_all('a', {'href': re.compile(link_pattern)})\n",
    "        for result in results:\n",
    "            links.append(result['href'])\n",
    "    print(f\"총 {len(links)}개의 뉴스 링크를 찾았습니다.\")  # 확인용\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c93999d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 페이지 별로 필요한 정보 스크레이핑\n",
    "\n",
    "def extract_info(url, wait_time=2, delay_time=0.5):\n",
    "    driver.implicitly_wait(wait_time)\n",
    "    driver.get(url)\n",
    "\n",
    "    # 댓글 창 있으면 다 내리기\n",
    "    while True:\n",
    "        try:\n",
    "            more_comments = driver.find_element_by_css_selector('a.u_cbox_btn_more')\n",
    "            more_comments.click()\n",
    "            time.sleep(delay_time)\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "   # html 페이지 읽어오기 \n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    result = []\n",
    "\n",
    "    try: # 연예 분야 뉴스 제외\n",
    "\n",
    "        site = soup.find('h1').find(\"span\").get_text(strip=True)  # 출처\n",
    "        title = soup.find('h3', {'id': 'articleTitle'}).get_text(strip=True)  # 기사 제목\n",
    "        article_time = soup.find('span', {'class': 't11'}).get_text(strip=True)  # 작성 시간\n",
    "\n",
    "        press = soup.find('div', {'class': \"press_logo\"}).find('a').find('img')['title']  # 언론사\n",
    "\n",
    "        total_com = soup.find(\"span\", {\"class\": \"u_cbox_info_txt\"}).get_text(strip=True)  # 댓글 수\n",
    "        total_com = int(total_com.replace('\\n', '').replace('\\t', '').replace('\\r', '').replace(',', ''))\n",
    "\n",
    "        if total_com == 0: # 댓글 없는 경우\n",
    "            result = [{'site': site,\n",
    "                       'title': title,\n",
    "                       'article_time': article_time,\n",
    "                       'press': press,\n",
    "                       'total_comments': total_com,\n",
    "                       'nickname': None,\n",
    "                       'date': None,\n",
    "                       'contents': None,\n",
    "                       'recomm': None,\n",
    "                       'unrecomm': None}]\n",
    "        else:\n",
    "            nicks = soup.find_all(\"span\", {\"class\": \"u_cbox_nick\"})  # 댓글 작성자\n",
    "            nicks = [nick.text for nick in nicks]\n",
    "\n",
    "            dates = soup.find_all(\"span\", {\"class\": \"u_cbox_date\"})  # 댓글 날짜\n",
    "            dates = [date.text for date in dates]\n",
    "\n",
    "            contents = soup.find_all(\"span\", {\"class\": \"u_cbox_contents\"})  # 댓글 내용\n",
    "            contents = [content.text for content in contents]\n",
    "\n",
    "            recomms = soup.find_all(\"em\", {\"class\": \"u_cbox_cnt_recomm\"})  # 공감 수\n",
    "            recomms = [recomm.text for recomm in recomms]\n",
    "\n",
    "            unrecomms = soup.find_all(\"em\", {\"class\": \"u_cbox_cnt_unrecomm\"})  # 비공감수\n",
    "            unrecomms = [unrecomm.text for unrecomm in unrecomms]\n",
    "\n",
    "            for i in range(len(contents)):\n",
    "                result.append({'site': site,\n",
    "                               'title': title,\n",
    "                               'article_time': article_time,\n",
    "                               'press': press,\n",
    "                               'total_comments': total_com,\n",
    "                               'nickname': nicks[i],\n",
    "                               'date': dates[i],\n",
    "                               'contents': contents[i].replace('\\r','').replace('\\t','').replace('\\n',''),\n",
    "                               'recomm': recomms[i],\n",
    "                               'unrecomm': unrecomms[i]})\n",
    "\n",
    "    except: # 연예 분야 뉴스인 경우 AttributeError.\n",
    "        pass\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc43e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 페이지 돌면서 스크레이핑\n",
    "\n",
    "def extract_contents(links):\n",
    "    for link in links:\n",
    "        print(f\"{link}&m_view=1\")\n",
    "        content = extract_info(f\"{link}&m_view=1\")\n",
    "        append_to_file(content)\n",
    "    return print(\"모든 작업이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3d3e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 만드는 함수\n",
    "\n",
    "def make_file():\n",
    "\n",
    "    if os.path.exists(f\"E:/scraping/news_comments_NAVER_{START_DATE}_{END_DATE}.csv\"):\n",
    "        raise NameError(\"동일한 파일이 존재합니다.\")\n",
    "\n",
    "    file = open(f\"news_comments_NAVER_{START_DATE}_{END_DATE}.csv\", mode=\"w\", encoding=\"UTF-8\")\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['site', 'title', 'article_time', 'press', 'total_comments', 'nickname', 'date', 'contents', 'recomm', 'unrecomm'])\n",
    "    file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e858c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일에 한 줄씩 덮어 쓰는 함수\n",
    "\n",
    "def append_to_file(lst):\n",
    "    global START_DATE\n",
    "    global END_DATE\n",
    "    file = open(f\"news_comments_NAVER_{START_DATE}_{END_DATE}.csv\", mode=\"a\", encoding=\"UTF-8\")\n",
    "    writer = csv.writer(file)\n",
    "    for result in lst:\n",
    "        writer.writerow(list(result.values()))\n",
    "    file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67da9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main 함수\n",
    "\n",
    "def main():\n",
    "    global search_PAGE\n",
    "    make_file()\n",
    "    news_links = get_news_links(search_PAGE, LINK_PAT)\n",
    "    result = extract_contents(news_links)\n",
    "    driver.quit()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dea5897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping page : 1\n",
      "200\n",
      "Scrapping page : 2\n",
      "200\n",
      "Scrapping page : 3\n",
      "200\n",
      "Scrapping page : 4\n",
      "200\n",
      "Scrapping page : 5\n",
      "200\n",
      "Scrapping page : 6\n",
      "200\n",
      "Scrapping page : 7\n",
      "200\n",
      "Scrapping page : 8\n",
      "200\n",
      "Scrapping page : 9\n",
      "200\n",
      "Scrapping page : 10\n",
      "200\n",
      "Scrapping page : 11\n",
      "200\n",
      "Scrapping page : 12\n",
      "200\n",
      "Scrapping page : 13\n",
      "200\n",
      "Scrapping page : 14\n",
      "200\n",
      "Scrapping page : 15\n",
      "200\n",
      "Scrapping page : 16\n",
      "200\n",
      "Scrapping page : 17\n",
      "200\n",
      "Scrapping page : 18\n",
      "200\n",
      "Scrapping page : 19\n",
      "200\n",
      "Scrapping page : 20\n",
      "200\n",
      "Scrapping page : 21\n",
      "200\n",
      "Scrapping page : 22\n",
      "200\n",
      "Scrapping page : 23\n",
      "200\n",
      "Scrapping page : 24\n",
      "200\n",
      "Scrapping page : 25\n",
      "200\n",
      "Scrapping page : 26\n",
      "200\n",
      "Scrapping page : 27\n",
      "200\n",
      "Scrapping page : 28\n",
      "200\n",
      "Scrapping page : 29\n",
      "200\n",
      "Scrapping page : 30\n",
      "200\n",
      "Scrapping page : 31\n",
      "200\n",
      "Scrapping page : 32\n",
      "200\n",
      "Scrapping page : 33\n",
      "200\n",
      "Scrapping page : 34\n",
      "200\n",
      "Scrapping page : 35\n",
      "200\n",
      "Scrapping page : 36\n",
      "200\n",
      "Scrapping page : 37\n",
      "200\n",
      "Scrapping page : 38\n",
      "200\n",
      "Scrapping page : 39\n",
      "200\n",
      "Scrapping page : 40\n",
      "200\n",
      "Scrapping page : 41\n",
      "200\n",
      "Scrapping page : 42\n",
      "200\n",
      "Scrapping page : 43\n",
      "200\n",
      "Scrapping page : 44\n",
      "200\n",
      "Scrapping page : 45\n",
      "200\n",
      "Scrapping page : 46\n",
      "200\n",
      "Scrapping page : 47\n",
      "200\n",
      "Scrapping page : 48\n",
      "200\n",
      "Scrapping page : 49\n",
      "200\n",
      "Scrapping page : 50\n",
      "200\n",
      "Scrapping page : 51\n",
      "200\n",
      "Scrapping page : 52\n",
      "200\n",
      "Scrapping page : 53\n",
      "200\n",
      "Scrapping page : 54\n",
      "200\n",
      "Scrapping page : 55\n",
      "200\n",
      "Scrapping page : 56\n",
      "200\n",
      "Scrapping page : 57\n",
      "200\n",
      "Scrapping page : 58\n",
      "200\n",
      "Scrapping page : 59\n",
      "200\n",
      "Scrapping page : 60\n",
      "200\n",
      "Scrapping page : 61\n",
      "200\n",
      "Scrapping page : 62\n",
      "200\n",
      "Scrapping page : 63\n",
      "200\n",
      "Scrapping page : 64\n",
      "200\n",
      "Scrapping page : 65\n",
      "200\n",
      "Scrapping page : 66\n",
      "200\n",
      "Scrapping page : 67\n",
      "200\n",
      "Scrapping page : 68\n",
      "200\n",
      "Scrapping page : 69\n",
      "200\n",
      "Scrapping page : 70\n",
      "200\n",
      "Scrapping page : 71\n",
      "200\n",
      "Scrapping page : 72\n",
      "200\n",
      "Scrapping page : 73\n",
      "200\n",
      "Scrapping page : 74\n",
      "200\n",
      "Scrapping page : 75\n",
      "200\n",
      "Scrapping page : 76\n",
      "200\n",
      "Scrapping page : 77\n",
      "200\n",
      "Scrapping page : 78\n",
      "200\n",
      "Scrapping page : 79\n",
      "200\n",
      "Scrapping page : 80\n",
      "200\n",
      "Scrapping page : 81\n",
      "200\n",
      "Scrapping page : 82\n",
      "200\n",
      "Scrapping page : 83\n",
      "200\n",
      "Scrapping page : 84\n",
      "200\n",
      "Scrapping page : 85\n",
      "200\n",
      "Scrapping page : 86\n",
      "200\n",
      "Scrapping page : 87\n",
      "200\n",
      "Scrapping page : 88\n",
      "200\n",
      "Scrapping page : 89\n",
      "200\n",
      "Scrapping page : 90\n",
      "200\n",
      "Scrapping page : 91\n",
      "200\n",
      "Scrapping page : 92\n",
      "200\n",
      "Scrapping page : 93\n",
      "200\n",
      "Scrapping page : 94\n",
      "200\n",
      "Scrapping page : 95\n",
      "200\n",
      "Scrapping page : 96\n",
      "200\n",
      "Scrapping page : 97\n",
      "200\n",
      "Scrapping page : 98\n",
      "200\n",
      "Scrapping page : 99\n",
      "200\n",
      "Scrapping page : 100\n",
      "200\n",
      "Scrapping page : 101\n",
      "200\n",
      "Scrapping page : 102\n",
      "200\n",
      "Scrapping page : 103\n",
      "200\n",
      "Scrapping page : 104\n",
      "200\n",
      "Scrapping page : 105\n",
      "200\n",
      "Scrapping page : 106\n",
      "200\n",
      "Scrapping page : 107\n",
      "200\n",
      "Scrapping page : 108\n",
      "200\n",
      "Scrapping page : 109\n",
      "200\n",
      "Scrapping page : 110\n",
      "200\n",
      "Scrapping page : 111\n",
      "200\n",
      "Scrapping page : 112\n",
      "200\n",
      "Scrapping page : 113\n",
      "200\n",
      "Scrapping page : 114\n",
      "200\n",
      "Scrapping page : 115\n",
      "200\n",
      "Scrapping page : 116\n",
      "200\n",
      "Scrapping page : 117\n",
      "200\n",
      "Scrapping page : 118\n",
      "200\n",
      "Scrapping page : 119\n",
      "200\n",
      "Scrapping page : 120\n",
      "200\n",
      "Scrapping page : 121\n",
      "200\n",
      "Scrapping page : 122\n",
      "200\n",
      "Scrapping page : 123\n",
      "200\n",
      "Scrapping page : 124\n",
      "200\n",
      "Scrapping page : 125\n",
      "200\n",
      "Scrapping page : 126\n",
      "200\n",
      "Scrapping page : 127\n",
      "200\n",
      "Scrapping page : 128\n",
      "200\n",
      "Scrapping page : 129\n",
      "200\n",
      "Scrapping page : 130\n",
      "200\n",
      "Scrapping page : 131\n",
      "200\n",
      "Scrapping page : 132\n",
      "200\n",
      "Scrapping page : 133\n",
      "200\n",
      "Scrapping page : 134\n",
      "200\n",
      "Scrapping page : 135\n",
      "200\n",
      "Scrapping page : 136\n",
      "200\n",
      "Scrapping page : 137\n",
      "200\n",
      "Scrapping page : 138\n",
      "200\n",
      "Scrapping page : 139\n",
      "200\n",
      "Scrapping page : 140\n",
      "200\n",
      "Scrapping page : 141\n",
      "200\n",
      "Scrapping page : 142\n",
      "200\n",
      "Scrapping page : 143\n",
      "200\n",
      "Scrapping page : 144\n",
      "200\n",
      "Scrapping page : 145\n",
      "200\n",
      "Scrapping page : 146\n",
      "200\n",
      "Scrapping page : 147\n",
      "200\n",
      "Scrapping page : 148\n",
      "200\n",
      "Scrapping page : 149\n",
      "200\n",
      "Scrapping page : 150\n",
      "200\n",
      "Scrapping page : 151\n",
      "200\n",
      "Scrapping page : 152\n",
      "200\n",
      "Scrapping page : 153\n",
      "200\n",
      "Scrapping page : 154\n",
      "200\n",
      "Scrapping page : 155\n",
      "200\n",
      "Scrapping page : 156\n",
      "200\n",
      "Scrapping page : 157\n",
      "200\n",
      "Scrapping page : 158\n",
      "200\n",
      "Scrapping page : 159\n",
      "200\n",
      "Scrapping page : 160\n",
      "200\n",
      "Scrapping page : 161\n",
      "200\n",
      "Scrapping page : 162\n",
      "200\n",
      "Scrapping page : 163\n",
      "200\n",
      "Scrapping page : 164\n",
      "200\n",
      "Scrapping page : 165\n",
      "200\n",
      "Scrapping page : 166\n",
      "200\n",
      "Scrapping page : 167\n",
      "200\n",
      "Scrapping page : 168\n",
      "200\n",
      "Scrapping page : 169\n",
      "200\n",
      "Scrapping page : 170\n",
      "200\n",
      "Scrapping page : 171\n",
      "200\n",
      "Scrapping page : 172\n",
      "200\n",
      "Scrapping page : 173\n",
      "200\n",
      "Scrapping page : 174\n",
      "200\n",
      "Scrapping page : 175\n",
      "200\n",
      "Scrapping page : 176\n",
      "200\n",
      "Scrapping page : 177\n",
      "200\n",
      "Scrapping page : 178\n",
      "200\n",
      "Scrapping page : 179\n",
      "200\n",
      "Scrapping page : 180\n",
      "200\n",
      "Scrapping page : 181\n",
      "200\n",
      "Scrapping page : 182\n",
      "200\n",
      "Scrapping page : 183\n",
      "200\n",
      "Scrapping page : 184\n",
      "200\n",
      "Scrapping page : 185\n",
      "200\n",
      "Scrapping page : 186\n",
      "200\n",
      "Scrapping page : 187\n",
      "200\n",
      "Scrapping page : 188\n",
      "200\n",
      "Scrapping page : 189\n",
      "200\n",
      "Scrapping page : 190\n",
      "200\n",
      "Scrapping page : 191\n",
      "200\n",
      "Scrapping page : 192\n",
      "200\n",
      "Scrapping page : 193\n",
      "200\n",
      "Scrapping page : 194\n",
      "200\n",
      "Scrapping page : 195\n",
      "200\n",
      "Scrapping page : 196\n",
      "200\n",
      "Scrapping page : 197\n",
      "200\n",
      "Scrapping page : 198\n",
      "200\n",
      "Scrapping page : 199\n",
      "200\n",
      "Scrapping page : 200\n",
      "200\n",
      "Scrapping page : 201\n",
      "200\n",
      "Scrapping page : 202\n",
      "200\n",
      "Scrapping page : 203\n",
      "200\n",
      "Scrapping page : 204\n",
      "200\n",
      "Scrapping page : 205\n",
      "200\n",
      "Scrapping page : 206\n",
      "200\n",
      "Scrapping page : 207\n",
      "200\n",
      "Scrapping page : 208\n",
      "200\n",
      "Scrapping page : 209\n",
      "200\n",
      "Scrapping page : 210\n",
      "200\n",
      "Scrapping page : 211\n",
      "200\n",
      "Scrapping page : 212\n",
      "200\n",
      "Scrapping page : 213\n",
      "200\n",
      "Scrapping page : 214\n",
      "200\n",
      "Scrapping page : 215\n",
      "200\n",
      "Scrapping page : 216\n",
      "200\n",
      "Scrapping page : 217\n",
      "200\n",
      "Scrapping page : 218\n",
      "200\n",
      "Scrapping page : 219\n",
      "200\n",
      "Scrapping page : 220\n",
      "200\n",
      "Scrapping page : 221\n",
      "200\n",
      "Scrapping page : 222\n",
      "200\n",
      "Scrapping page : 223\n",
      "200\n",
      "Scrapping page : 224\n",
      "200\n",
      "Scrapping page : 225\n",
      "200\n",
      "Scrapping page : 226\n",
      "200\n",
      "Scrapping page : 227\n",
      "200\n",
      "Scrapping page : 228\n",
      "200\n",
      "Scrapping page : 229\n",
      "200\n",
      "Scrapping page : 230\n",
      "200\n",
      "Scrapping page : 231\n",
      "200\n",
      "Scrapping page : 232\n",
      "200\n",
      "Scrapping page : 233\n",
      "200\n",
      "Scrapping page : 234\n",
      "200\n",
      "Scrapping page : 235\n",
      "200\n",
      "Scrapping page : 236\n",
      "200\n",
      "Scrapping page : 237\n",
      "200\n",
      "Scrapping page : 238\n",
      "200\n",
      "Scrapping page : 239\n",
      "200\n",
      "Scrapping page : 240\n",
      "200\n",
      "Scrapping page : 241\n",
      "200\n",
      "Scrapping page : 242\n",
      "200\n",
      "Scrapping page : 243\n",
      "200\n",
      "Scrapping page : 244\n",
      "200\n",
      "Scrapping page : 245\n",
      "200\n",
      "Scrapping page : 246\n",
      "200\n",
      "Scrapping page : 247\n",
      "200\n",
      "Scrapping page : 248\n",
      "200\n",
      "Scrapping page : 249\n",
      "200\n",
      "Scrapping page : 250\n",
      "200\n",
      "Scrapping page : 251\n",
      "200\n",
      "Scrapping page : 252\n",
      "200\n",
      "Scrapping page : 253\n",
      "200\n",
      "Scrapping page : 254\n",
      "200\n",
      "Scrapping page : 255\n",
      "200\n",
      "Scrapping page : 256\n",
      "200\n",
      "Scrapping page : 257\n",
      "200\n",
      "Scrapping page : 258\n",
      "200\n",
      "Scrapping page : 259\n",
      "200\n",
      "Scrapping page : 260\n",
      "200\n",
      "Scrapping page : 261\n",
      "200\n",
      "Scrapping page : 262\n",
      "200\n",
      "Scrapping page : 263\n",
      "200\n",
      "Scrapping page : 264\n",
      "200\n",
      "Scrapping page : 265\n",
      "200\n",
      "Scrapping page : 266\n",
      "200\n",
      "Scrapping page : 267\n",
      "200\n",
      "Scrapping page : 268\n",
      "200\n",
      "Scrapping page : 269\n",
      "200\n",
      "Scrapping page : 270\n",
      "200\n",
      "Scrapping page : 271\n",
      "200\n",
      "Scrapping page : 272\n",
      "200\n",
      "Scrapping page : 273\n",
      "200\n",
      "Scrapping page : 274\n",
      "200\n",
      "Scrapping page : 275\n",
      "200\n",
      "Scrapping page : 276\n",
      "200\n",
      "Scrapping page : 277\n",
      "200\n",
      "Scrapping page : 278\n",
      "200\n",
      "Scrapping page : 279\n",
      "200\n",
      "Scrapping page : 280\n",
      "200\n",
      "Scrapping page : 281\n",
      "200\n",
      "Scrapping page : 282\n",
      "200\n",
      "Scrapping page : 283\n",
      "200\n",
      "Scrapping page : 284\n",
      "200\n",
      "Scrapping page : 285\n",
      "200\n",
      "Scrapping page : 286\n",
      "200\n",
      "Scrapping page : 287\n",
      "200\n",
      "Scrapping page : 288\n",
      "200\n",
      "Scrapping page : 289\n",
      "200\n",
      "Scrapping page : 290\n",
      "200\n",
      "Scrapping page : 291\n",
      "200\n",
      "Scrapping page : 292\n",
      "200\n",
      "Scrapping page : 293\n",
      "200\n",
      "Scrapping page : 294\n",
      "200\n",
      "Scrapping page : 295\n",
      "200\n",
      "Scrapping page : 296\n",
      "200\n",
      "Scrapping page : 297\n",
      "200\n",
      "Scrapping page : 298\n",
      "200\n",
      "Scrapping page : 299\n",
      "200\n",
      "Scrapping page : 300\n",
      "200\n",
      "Scrapping page : 301\n",
      "200\n",
      "Scrapping page : 302\n",
      "200\n",
      "Scrapping page : 303\n",
      "200\n",
      "Scrapping page : 304\n",
      "200\n",
      "Scrapping page : 305\n",
      "200\n",
      "Scrapping page : 306\n",
      "200\n",
      "Scrapping page : 307\n",
      "200\n",
      "Scrapping page : 308\n",
      "200\n",
      "Scrapping page : 309\n",
      "200\n",
      "Scrapping page : 310\n",
      "200\n",
      "Scrapping page : 311\n",
      "200\n",
      "Scrapping page : 312\n",
      "200\n",
      "Scrapping page : 313\n",
      "200\n",
      "Scrapping page : 314\n",
      "200\n",
      "Scrapping page : 315\n",
      "200\n",
      "Scrapping page : 316\n",
      "200\n",
      "Scrapping page : 317\n",
      "200\n",
      "Scrapping page : 318\n",
      "200\n",
      "Scrapping page : 319\n",
      "200\n",
      "Scrapping page : 320\n",
      "200\n",
      "Scrapping page : 321\n",
      "200\n",
      "Scrapping page : 322\n",
      "200\n",
      "Scrapping page : 323\n",
      "200\n",
      "Scrapping page : 324\n",
      "200\n",
      "Scrapping page : 325\n",
      "200\n",
      "Scrapping page : 326\n",
      "200\n",
      "총 0개의 뉴스 링크를 찾았습니다.\n",
      "모든 작업이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19176b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
